{"cells":[{"metadata":{"id":"q4gSqDnOaJ7W"},"cell_type":"markdown","source":"<img align=center src=\"https://rhyme.com/assets/img/logo-dark.png\"></img>\n<h2 align=center> Named Entity Recognition (NER) using LSTMs with Keras</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/input/ner_dataset.csv\n","name":"stdout"}]},{"metadata":{"id":"oLK7Y1jiNXDa","outputId":"0f319464-ee49-4035-f6fb-8396f488c41f","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nnp.random.seed(0)\nplt.style.use(\"ggplot\")\n\nimport tensorflow as tf\nprint('Tensorflow version:', tf.__version__)","execution_count":3,"outputs":[{"output_type":"stream","text":"Tensorflow version: 2.1.0\n","name":"stdout"}]},{"metadata":{"id":"4N_AW6lMbB5N"},"cell_type":"markdown","source":"### Loading and Exploring the NER Dataset"},{"metadata":{},"cell_type":"markdown","source":"*Essential info about the tagged entities*:\n- geo = Geographical Entity\n- org = Organization\n- per = Person\n- gpe = Geopolitical Entity\n- tim = Time indicator\n- art = Artifact\n- eve = Event\n- nat = Natural Phenomenon"},{"metadata":{"id":"mCKmz4SAbI_m","outputId":"a03b1aed-dc60-4f03-cb06-19e440fa6367","trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/ner_dataset.csv\",encoding='latin1')\ndf.head(30)","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"     Sentence #           Word  POS    Tag\n0   Sentence: 1      Thousands  NNS      O\n1           NaN             of   IN      O\n2           NaN  demonstrators  NNS      O\n3           NaN           have  VBP      O\n4           NaN        marched  VBN      O\n5           NaN        through   IN      O\n6           NaN         London  NNP  B-geo\n7           NaN             to   TO      O\n8           NaN        protest   VB      O\n9           NaN            the   DT      O\n10          NaN            war   NN      O\n11          NaN             in   IN      O\n12          NaN           Iraq  NNP  B-geo\n13          NaN            and   CC      O\n14          NaN         demand   VB      O\n15          NaN            the   DT      O\n16          NaN     withdrawal   NN      O\n17          NaN             of   IN      O\n18          NaN        British   JJ  B-gpe\n19          NaN         troops  NNS      O\n20          NaN           from   IN      O\n21          NaN           that   DT      O\n22          NaN        country   NN      O\n23          NaN              .    .      O\n24  Sentence: 2       Families  NNS      O\n25          NaN             of   IN      O\n26          NaN       soldiers  NNS      O\n27          NaN         killed  VBN      O\n28          NaN             in   IN      O\n29          NaN            the   DT      O","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Word</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sentence: 1</td>\n      <td>Thousands</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>demonstrators</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>have</td>\n      <td>VBP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>marched</td>\n      <td>VBN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>through</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NaN</td>\n      <td>London</td>\n      <td>NNP</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NaN</td>\n      <td>to</td>\n      <td>TO</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>NaN</td>\n      <td>protest</td>\n      <td>VB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NaN</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>NaN</td>\n      <td>war</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NaN</td>\n      <td>in</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>NaN</td>\n      <td>Iraq</td>\n      <td>NNP</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>NaN</td>\n      <td>and</td>\n      <td>CC</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>NaN</td>\n      <td>demand</td>\n      <td>VB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>NaN</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>NaN</td>\n      <td>withdrawal</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>NaN</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>NaN</td>\n      <td>British</td>\n      <td>JJ</td>\n      <td>B-gpe</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>NaN</td>\n      <td>troops</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>NaN</td>\n      <td>from</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>NaN</td>\n      <td>that</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>NaN</td>\n      <td>country</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>NaN</td>\n      <td>.</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Sentence: 2</td>\n      <td>Families</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>NaN</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>NaN</td>\n      <td>soldiers</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>NaN</td>\n      <td>killed</td>\n      <td>VBN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>NaN</td>\n      <td>in</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>NaN</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"id":"riOztP-8NXHT","outputId":"200d251b-17c9-451b-9e96-523f458be47e","trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"Sentence #    1000616\nWord                0\nPOS                 0\nTag                 0\ndtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Looking at the dataset here we will use ffill feature to fill the null values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.fillna(method='ffill')\ndf.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"    Sentence #           Word  POS Tag\n0  Sentence: 1      Thousands  NNS   O\n1  Sentence: 1             of   IN   O\n2  Sentence: 1  demonstrators  NNS   O\n3  Sentence: 1           have  VBP   O\n4  Sentence: 1        marched  VBN   O","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Word</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sentence: 1</td>\n      <td>Thousands</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sentence: 1</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sentence: 1</td>\n      <td>demonstrators</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sentence: 1</td>\n      <td>have</td>\n      <td>VBP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sentence: 1</td>\n      <td>marched</td>\n      <td>VBN</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"Sentence #    0\nWord          0\nPOS           0\nTag           0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Tag'].value_counts()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"O        887908\nB-geo     37644\nB-tim     20333\nB-org     20143\nI-per     17251\nB-per     16990\nI-org     16784\nB-gpe     15870\nI-geo      7414\nI-tim      6528\nB-art       402\nB-eve       308\nI-art       297\nI-eve       253\nB-nat       201\nI-gpe       198\nI-nat        51\nName: Tag, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_tags=df['Tag'].nunique()\nn_tags","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"17"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_words=df['Word'].nunique()\nn_words","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"35178"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"words=list(set(df['Word']))","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# words","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tags=list(set(df['Tag']))","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tags","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"['I-tim',\n 'I-nat',\n 'I-geo',\n 'I-art',\n 'B-geo',\n 'B-per',\n 'B-gpe',\n 'I-per',\n 'B-org',\n 'B-nat',\n 'B-tim',\n 'I-gpe',\n 'O',\n 'I-org',\n 'B-eve',\n 'I-eve',\n 'B-art']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class GetSentence(object):\n    def __init__(self, data):\n        self.n_sentence=1\n        self.data=data\n        self.empty = False\n        function=lambda d:[(w, p, t) for w, p, t in zip(d[\"Word\"].values.tolist(),\n                                                        d[\"POS\"].values.tolist(),\n                                                        d[\"Tag\"].values.tolist())]\n        \n        self.group_sent = self.data.groupby(\"Sentence #\").apply(function)\n        self.all_sentences = [d for d in self.group_sent] ","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get=GetSentence(df)\nsentences=get.all_sentences","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences[0]","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"[('Thousands', 'NNS', 'O'),\n ('of', 'IN', 'O'),\n ('demonstrators', 'NNS', 'O'),\n ('have', 'VBP', 'O'),\n ('marched', 'VBN', 'O'),\n ('through', 'IN', 'O'),\n ('London', 'NNP', 'B-geo'),\n ('to', 'TO', 'O'),\n ('protest', 'VB', 'O'),\n ('the', 'DT', 'O'),\n ('war', 'NN', 'O'),\n ('in', 'IN', 'O'),\n ('Iraq', 'NNP', 'B-geo'),\n ('and', 'CC', 'O'),\n ('demand', 'VB', 'O'),\n ('the', 'DT', 'O'),\n ('withdrawal', 'NN', 'O'),\n ('of', 'IN', 'O'),\n ('British', 'JJ', 'B-gpe'),\n ('troops', 'NNS', 'O'),\n ('from', 'IN', 'O'),\n ('that', 'DT', 'O'),\n ('country', 'NN', 'O'),\n ('.', '.', 'O')]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences[6]","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"[('He', 'PRP', 'O'),\n ('said', 'VBD', 'O'),\n ('last', 'JJ', 'O'),\n ('week', 'NN', 'O'),\n (\"'s\", 'POS', 'O'),\n ('tsunami', 'NN', 'O'),\n ('and', 'CC', 'O'),\n ('the', 'DT', 'O'),\n ('massive', 'JJ', 'O'),\n ('underwater', 'NN', 'O'),\n ('earthquake', 'NN', 'O'),\n ('that', 'WDT', 'O'),\n ('triggered', 'VBD', 'O'),\n ('it', 'PRP', 'O'),\n ('has', 'VBZ', 'O'),\n ('affected', 'VBN', 'O'),\n ('millions', 'NNS', 'O'),\n ('in', 'IN', 'O'),\n ('Asia', 'NNP', 'B-geo'),\n ('and', 'CC', 'O'),\n ('Africa', 'NNP', 'B-geo'),\n ('.', '.', 'O')]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(sentences)","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"47959"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# For the input of LSTM model all the sentences must be padded to same length,for that we must know the maximum length of the sequence in th elist of sentences."},{"metadata":{"trusted":true},"cell_type":"code","source":"maxl = max([len(s) for s in sentences])\nprint ('Maximum sequence length in the list of sentences:', maxl)","execution_count":36,"outputs":[{"output_type":"stream","text":"Maximum sequence length in the list of sentences: 104\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# We had splitted each sentences as a list of tuples of the word,POS and tags."},{"metadata":{"trusted":true},"cell_type":"code","source":"w_index={w:i+1 for i,w in enumerate(words)}\nt_index={t:j+1 for j,t in enumerate(tags)}","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# w_index","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# t_index","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"VdJst_g5NYY_","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"nMUQLppspkPj","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"GhiSTt2UdzYC","outputId":"95d275f6-f386-46d8-a583-2861d64c6b72","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"SvENHO18pkaQ","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"P-r4PR85hpoF"},"cell_type":"markdown","source":"### Task 6: Build and Compile a Bidirectional LSTM Model"},{"metadata":{"id":"Y2vM7IkXpkiH","trusted":true},"cell_type":"code","source":"from tensorflow.keras import Model, Input\nfrom tensorflow.keras.layers import LSTM, Embedding, Dense\nfrom tensorflow.keras.layers import TimeDistributed, SpatialDropout1D, Bidirectional","execution_count":null,"outputs":[]},{"metadata":{"id":"Aee3mCZ3pkkv","outputId":"b7fb911b-21d1-43e6-adc9-bb2d8bdfb921","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"kOBpQg26pkqh","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"My0tL0cciMXQ"},"cell_type":"markdown","source":"### Task 7: Train the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom livelossplot.tf_keras import PlotLossesCallback","execution_count":null,"outputs":[]},{"metadata":{"id":"Q9HWH06Ypkxh","outputId":"e83ba281-0c14-4bca-dacb-cb708edacba5","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"2nwnnF0ziU3B"},"cell_type":"markdown","source":"### Task 8: Evaluate Named Entity Recognition Model"},{"metadata":{"id":"6euqX7UHplG7","outputId":"7222c24c-52c5-454b-a5d4-03d6df4173f0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"Tyg4mKOVplJ-","outputId":"59e897c3-cb77-4dc2-a239-dea2c94eec42","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"NER.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":4}